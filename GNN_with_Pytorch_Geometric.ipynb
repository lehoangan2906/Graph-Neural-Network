{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ca533739efc4bb2ab2a7e165e41438e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00e6470e963d4931ba29bc423abf4dc1",
              "IPY_MODEL_04a9f6721d7a46cfa7c533203b979532",
              "IPY_MODEL_c6f1b4bd7a6a4be7a95892d50292a953"
            ],
            "layout": "IPY_MODEL_704322f8fd6a4e709e1b79e85a69c859"
          }
        },
        "00e6470e963d4931ba29bc423abf4dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fb72794d3ea4d36a54f411d2505a435",
            "placeholder": "​",
            "style": "IPY_MODEL_b8ad5da6a92b4a519dc62b61155e9750",
            "value": "100%"
          }
        },
        "04a9f6721d7a46cfa7c533203b979532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36b7d2a92e644558abcfa6847bb8955d",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d40b8233f69d40608a8730f781a26fa5",
            "value": 9912422
          }
        },
        "c6f1b4bd7a6a4be7a95892d50292a953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f36873e56b5c4e11ab66fbcedf5929c4",
            "placeholder": "​",
            "style": "IPY_MODEL_f7d281846b6343708ef78cf5c6687f77",
            "value": " 9912422/9912422 [00:00&lt;00:00, 179688176.63it/s]"
          }
        },
        "704322f8fd6a4e709e1b79e85a69c859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb72794d3ea4d36a54f411d2505a435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8ad5da6a92b4a519dc62b61155e9750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36b7d2a92e644558abcfa6847bb8955d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d40b8233f69d40608a8730f781a26fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f36873e56b5c4e11ab66fbcedf5929c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d281846b6343708ef78cf5c6687f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1186be0a19042b1bd14e870aeba5a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fba56b7801354a898256d539b255fb2d",
              "IPY_MODEL_5426b74c7e9447bab266dcffb8c14fa4",
              "IPY_MODEL_efb21272c37f4bf0aeae36e0ae5c757b"
            ],
            "layout": "IPY_MODEL_daf82c7f3df84de0a345337c0d2342c2"
          }
        },
        "fba56b7801354a898256d539b255fb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_018eb60b637140e38b624027cb075212",
            "placeholder": "​",
            "style": "IPY_MODEL_82994a0db3ab44fda8bd0ce631fb3ee4",
            "value": "100%"
          }
        },
        "5426b74c7e9447bab266dcffb8c14fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51f8f0efa298417eb19725ee6d1cb38c",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c36fca0bbd324fdeb1ab5e93eebb0f22",
            "value": 28881
          }
        },
        "efb21272c37f4bf0aeae36e0ae5c757b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_568e28ccce6742f3bf8dacd393a1e609",
            "placeholder": "​",
            "style": "IPY_MODEL_b9b7933f5a674ee5a7d11031bfeedd6c",
            "value": " 28881/28881 [00:00&lt;00:00, 1093618.02it/s]"
          }
        },
        "daf82c7f3df84de0a345337c0d2342c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "018eb60b637140e38b624027cb075212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82994a0db3ab44fda8bd0ce631fb3ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51f8f0efa298417eb19725ee6d1cb38c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c36fca0bbd324fdeb1ab5e93eebb0f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "568e28ccce6742f3bf8dacd393a1e609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b7933f5a674ee5a7d11031bfeedd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d1016533dd94c67808487de042f70ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aeeaf8e04897492cac4d27a18f75eda2",
              "IPY_MODEL_d33dd8605c0643bf866f6da29c1141a1",
              "IPY_MODEL_cac3418167564dcba787e684bc07c6ec"
            ],
            "layout": "IPY_MODEL_e66d6b31398d48b6a5e9fd53198d841a"
          }
        },
        "aeeaf8e04897492cac4d27a18f75eda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a67ea54a93b84670ab3d76f232ea8061",
            "placeholder": "​",
            "style": "IPY_MODEL_f821ce4f12564516b4f7c976fc4cb9fe",
            "value": "100%"
          }
        },
        "d33dd8605c0643bf866f6da29c1141a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3a73a58688f432fb0d02d06ffb5c4f2",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58f2df1658084ad48d6b7fa9aa37591d",
            "value": 1648877
          }
        },
        "cac3418167564dcba787e684bc07c6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a3080914972474fac3af373fc78678c",
            "placeholder": "​",
            "style": "IPY_MODEL_61ab228d19514fa2b166abb0268c61c2",
            "value": " 1648877/1648877 [00:00&lt;00:00, 5876766.28it/s]"
          }
        },
        "e66d6b31398d48b6a5e9fd53198d841a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a67ea54a93b84670ab3d76f232ea8061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f821ce4f12564516b4f7c976fc4cb9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3a73a58688f432fb0d02d06ffb5c4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58f2df1658084ad48d6b7fa9aa37591d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a3080914972474fac3af373fc78678c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ab228d19514fa2b166abb0268c61c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "605588cd03a44c729fb338a0392c8522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_454eeb9f5fbe47dabca96950c67e25c8",
              "IPY_MODEL_99c9569cb99c4dc9a36b80913be3b5be",
              "IPY_MODEL_413919b865014404853e393f737ed2c5"
            ],
            "layout": "IPY_MODEL_d037890c98ae43b09296582ecf666fd9"
          }
        },
        "454eeb9f5fbe47dabca96950c67e25c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7132476561e44623ab7009a8c23b2259",
            "placeholder": "​",
            "style": "IPY_MODEL_7f690740a0b240c4bf271f8b7c45123b",
            "value": "100%"
          }
        },
        "99c9569cb99c4dc9a36b80913be3b5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_014ad24dbea341d98d319812a150e7c0",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f99655748daa44f7ab224ac945706422",
            "value": 4542
          }
        },
        "413919b865014404853e393f737ed2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46d368f8f9fc4067989023403e6c3797",
            "placeholder": "​",
            "style": "IPY_MODEL_ba42bab020144a5ba053a95e02941601",
            "value": " 4542/4542 [00:00&lt;00:00, 155368.66it/s]"
          }
        },
        "d037890c98ae43b09296582ecf666fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7132476561e44623ab7009a8c23b2259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f690740a0b240c4bf271f8b7c45123b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "014ad24dbea341d98d319812a150e7c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99655748daa44f7ab224ac945706422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46d368f8f9fc4067989023403e6c3797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba42bab020144a5ba053a95e02941601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "    !pip install -U scikit-learn"
      ],
      "metadata": {
        "id": "KCQmTCykO0n_",
        "outputId": "851c96e1-dcee-458d-8e5a-23c64f718100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "Successfully installed scikit-learn-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRFZTcE4Mz6a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn   # has a lot of modules on neural network\n",
        "import torch.nn.functional as F   # has a lot of function definitions that related to neural network operations\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import sklearn.metrics as metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 12\n",
        "\n",
        "## transformations\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "## Download and load training datase\n",
        "trainset = torchvision.datasets.MNIST(root = './data', train = True, download = True, transform = transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)\n",
        "\n",
        "## Download and load testing dataset\n",
        "testset = torchvision.datasets.MNIST(root ='./data', train = True, download = True, transform = transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = BATCH_SIZE, shuffle = False, num_workers = 2)"
      ],
      "metadata": {
        "id": "bZ-3NTHoNBCW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "5ca533739efc4bb2ab2a7e165e41438e",
            "00e6470e963d4931ba29bc423abf4dc1",
            "04a9f6721d7a46cfa7c533203b979532",
            "c6f1b4bd7a6a4be7a95892d50292a953",
            "704322f8fd6a4e709e1b79e85a69c859",
            "1fb72794d3ea4d36a54f411d2505a435",
            "b8ad5da6a92b4a519dc62b61155e9750",
            "36b7d2a92e644558abcfa6847bb8955d",
            "d40b8233f69d40608a8730f781a26fa5",
            "f36873e56b5c4e11ab66fbcedf5929c4",
            "f7d281846b6343708ef78cf5c6687f77",
            "f1186be0a19042b1bd14e870aeba5a2d",
            "fba56b7801354a898256d539b255fb2d",
            "5426b74c7e9447bab266dcffb8c14fa4",
            "efb21272c37f4bf0aeae36e0ae5c757b",
            "daf82c7f3df84de0a345337c0d2342c2",
            "018eb60b637140e38b624027cb075212",
            "82994a0db3ab44fda8bd0ce631fb3ee4",
            "51f8f0efa298417eb19725ee6d1cb38c",
            "c36fca0bbd324fdeb1ab5e93eebb0f22",
            "568e28ccce6742f3bf8dacd393a1e609",
            "b9b7933f5a674ee5a7d11031bfeedd6c",
            "9d1016533dd94c67808487de042f70ee",
            "aeeaf8e04897492cac4d27a18f75eda2",
            "d33dd8605c0643bf866f6da29c1141a1",
            "cac3418167564dcba787e684bc07c6ec",
            "e66d6b31398d48b6a5e9fd53198d841a",
            "a67ea54a93b84670ab3d76f232ea8061",
            "f821ce4f12564516b4f7c976fc4cb9fe",
            "e3a73a58688f432fb0d02d06ffb5c4f2",
            "58f2df1658084ad48d6b7fa9aa37591d",
            "6a3080914972474fac3af373fc78678c",
            "61ab228d19514fa2b166abb0268c61c2",
            "605588cd03a44c729fb338a0392c8522",
            "454eeb9f5fbe47dabca96950c67e25c8",
            "99c9569cb99c4dc9a36b80913be3b5be",
            "413919b865014404853e393f737ed2c5",
            "d037890c98ae43b09296582ecf666fd9",
            "7132476561e44623ab7009a8c23b2259",
            "7f690740a0b240c4bf271f8b7c45123b",
            "014ad24dbea341d98d319812a150e7c0",
            "f99655748daa44f7ab224ac945706422",
            "46d368f8f9fc4067989023403e6c3797",
            "ba42bab020144a5ba053a95e02941601"
          ]
        },
        "outputId": "1064c7dd-99d0-4491-9c83-2852a4e8579b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ca533739efc4bb2ab2a7e165e41438e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1186be0a19042b1bd14e870aeba5a2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d1016533dd94c67808487de042f70ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "605588cd03a44c729fb338a0392c8522"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(trainset))\n",
        "print(trainset[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnJB0r7XQRDe",
        "outputId": "8179003f-4c43-4352-df8d-ae99c5e3eb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.1647, 0.4627, 0.8588, 0.6510, 0.4627,\n",
            "          0.4627, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.4039, 0.9490, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0706, 0.9098, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9333, 0.2745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.4078, 0.9569, 0.9961, 0.8784, 0.9961,\n",
            "          0.9961, 0.9961, 0.5529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9961, 0.8235, 0.9961,\n",
            "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.8078, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.8196, 0.9961,\n",
            "          0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 0.5373, 0.9922, 0.9961,\n",
            "          0.9961, 0.9961, 0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.1569, 0.8392, 0.9804, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.3176, 0.9686, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.5725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.4314, 0.9647, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.3490, 0.3490, 0.3647,\n",
            "          0.9412, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
            "          0.5020, 0.9961, 0.8588, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275,\n",
            "          0.9961, 0.9961, 0.8392, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5412,\n",
            "          0.9961, 0.9961, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.6941,\n",
            "          0.3529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.9412,\n",
            "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.9961,\n",
            "          0.8431, 0.2471, 0.1412, 0.0000, 0.2000, 0.3490, 0.8078, 0.9961,\n",
            "          0.9961, 0.5451, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.7725,\n",
            "          0.9961, 0.9961, 0.8706, 0.7059, 0.9451, 0.9961, 0.9961, 0.9922,\n",
            "          0.8353, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490,\n",
            "          0.4118, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9255,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0275, 0.4588, 0.4588, 0.6471, 0.9961, 0.9961, 0.9373, 0.1961,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]]), 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal here will be to train a model to classify  digits based on their pictures. Let's define the model we'll use for this task, which will consist of a convolutional layer followed by two fully-connected layers. Our model is a subclass od `nn.Module`, modules must implement a `forward()` function which defines exactly what operations get applied to the inputted data.\n",
        "\n",
        "Note that `MyModel` makes used of the predefined modules `Conv2d` and `Linear`, which is instantiates in its contructor. Running data `x` through a module `conv1` simply consists of calling it like a function: `out = conv1(x)`."
      ],
      "metadata": {
        "id": "ir5SxtXkMYHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "\n",
        "    # 28x28x1 => 26x26x32\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3)\n",
        "    self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
        "    self.d2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # 32 x 1 x 28 x 28 => 32 x 32 x 26 x 26\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # flatten => 32 x ( 32 * 26 * 26)\n",
        "    x = x.flatten(start_dim = 1)\n",
        "\n",
        "    # 32 x (32 * 26 * 26) => 32 x 128\n",
        "    x = self.d1(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # logits => 32 x 10\n",
        "    logits = self.d2(x)\n",
        "    out = F.softmax(logits, dim = 1)\n",
        "    return out"
      ],
      "metadata": {
        "id": "5zlvGjD_NUPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train our model, printing out its training accuracy along the way. We start by instantiating a model instance model, a loss function module criterion and optimizer, which will adjust the parameters of our model in order to minimize the loss output by criterion."
      ],
      "metadata": {
        "id": "l9QD3CiYOwlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([[1, 2], [3, 4]])\n",
        "b = np.ones((2, 2))\n",
        "\n",
        "ta = torch.tensor(a, dtype = float).to('cuda:0')\n",
        "tb = torch.ones(2, 2, dtype = float).to('cuda:0')\n",
        "\n",
        "print(ta)\n",
        "print(ta @ tb)"
      ],
      "metadata": {
        "id": "gyNCqK-rOu7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28745f45-46a2-4977-b67b-3cc531fa4caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]], device='cuda:0', dtype=torch.float64)\n",
            "tensor([[3., 3.],\n",
            "        [7., 7.]], device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train our model, printing out its training accuracy along the way. We start by instantiating a model instance `model`, a loss function module `criterion` and optimizer `optimizer`, which will adjust the parameters of our model in order to minimize the loss output by `criterion`."
      ],
      "metadata": {
        "id": "Hby4uTbNjwOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MyModel()\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "wZRodx-W6FJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's write our training loop. For each minibatch (accessed by enumerating through our data loader `trainloader`), we run our data through`model` in a forward pass, then compute the loss with `criterion`. We call `optimizer.zero_grad()` to zero out the gradients from the previous rouund of training, followed by `loss.backward()` to backpropagate the new round of gradients and finally `optimizer.step()` to adjust the model parameters based on these gradients."
      ],
      "metadata": {
        "id": "a6OeEWLxkqFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  train_running_loss = 0.0\n",
        "  train_acc = 0.0\n",
        "\n",
        "  ## training step\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    ## forward + backprop + loss\n",
        "    logits = model(images)\n",
        "    loss = criterion(logits, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    ##  update model params\n",
        "    optimizer.step()\n",
        "\n",
        "    train_running_loss += loss.detach().item()\n",
        "    train_acc += (torch.argmax(logits, 1). flatten() == labels).type(torch.float).mean().item()\n",
        "\n",
        "  print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f'%(epoch, train_running_loss / i, train_acc/i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkoURfQakYey",
        "outputId": "b6fb3ac9-7ebe-4c40-8da1-6a3dae505c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 1.5588 | Train Accuracy: 0.91\n",
            "Epoch: 1 | Loss: 1.4884 | Train Accuracy: 0.97\n",
            "Epoch: 2 | Loss: 1.4807 | Train Accuracy: 0.98\n",
            "Epoch: 3 | Loss: 1.4782 | Train Accuracy: 0.98\n",
            "Epoch: 4 | Loss: 1.4755 | Train Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we can run just the forward pass of our model in order to run it on the test set."
      ],
      "metadata": {
        "id": "zLdxhjkWn2Un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = 0.0\n",
        "for i, (images, labels) in enumerate(testloader, 0):\n",
        "  images = images.to(device)\n",
        "  labels = labels.to(device)\n",
        "  outputs = model(images)\n",
        "  test_acc += (torch.argmax(outputs, 1).flatten() == labels).type(torch.float).mean().item()\n",
        "  preds = torch.argmax(outputs, 1).flatten().cpu().numpy()\n",
        "\n",
        "print('Test Accuracy: %.2f'%(test_acc/i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnPfoF8bnypH",
        "outputId": "163a9ad0-2724-496d-a4b6-e5b9cf5cfbde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Let's first install PyTorch Geometric (which we'll use for Creating graph Neural Networks) and TensorboardX (which we'll use to visualize training progress):\n"
      ],
      "metadata": {
        "id": "pp1f7dPryGxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --verbose --no-cache-dir torch-scatter\n",
        "!pip install --verbose --no-cache-dir torch-sparse\n",
        "!pip install --verbose --no-cache-dir torch-cluster\n",
        "!pip install --verbose --no-cache-dir torch-spline-conv\n",
        "!pip install torch-geometric\n",
        "!pip install tensorboardX\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M77mbTAEogwy",
        "outputId": "6c725295-bee4-4b89-9353-2b3676eeb6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 22.0.4 from /usr/local/lib/python3.8/dist-packages/pip (python 3.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.0.tar.gz (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-hk7hkbz7/torch_scatter.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-hk7hkbz7/torch_scatter.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-hk7hkbz7/torch_scatter.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-hk7hkbz7/torch_scatter.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-hk7hkbz7/torch_scatter.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-hk7hkbz7/torch_scatter.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-hk7hkbz7/torch_scatter.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no previously-included files matching '*' found under directory 'test'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-hk7hkbz7/torch_scatter.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Running command python setup.py bdist_wheel\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  Generating grammar tables from /usr/lib/python3.8/lib2to3/Grammar.txt\n",
            "  Generating grammar tables from /usr/lib/python3.8/lib2to3/PatternGrammar.txt\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.8\n",
            "  creating build/lib.linux-x86_64-3.8/torch_scatter\n",
            "  copying torch_scatter/__init__.py -> build/lib.linux-x86_64-3.8/torch_scatter\n",
            "  copying torch_scatter/utils.py -> build/lib.linux-x86_64-3.8/torch_scatter\n",
            "  copying torch_scatter/segment_csr.py -> build/lib.linux-x86_64-3.8/torch_scatter\n",
            "  copying torch_scatter/placeholder.py -> build/lib.linux-x86_64-3.8/torch_scatter\n",
            "  copying torch_scatter/scatter.py -> build/lib.linux-x86_64-3.8/torch_scatter\n",
            "  copying torch_scatter/segment_coo.py -> build/lib.linux-x86_64-3.8/torch_scatter\n",
            "  creating build/lib.linux-x86_64-3.8/torch_scatter/composite\n",
            "  copying torch_scatter/composite/__init__.py -> build/lib.linux-x86_64-3.8/torch_scatter/composite\n",
            "  copying torch_scatter/composite/logsumexp.py -> build/lib.linux-x86_64-3.8/torch_scatter/composite\n",
            "  copying torch_scatter/composite/softmax.py -> build/lib.linux-x86_64-3.8/torch_scatter/composite\n",
            "  copying torch_scatter/composite/std.py -> build/lib.linux-x86_64-3.8/torch_scatter/composite\n",
            "  running egg_info\n",
            "  writing torch_scatter.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
            "  writing requirements to torch_scatter.egg-info/requires.txt\n",
            "  writing top-level names to torch_scatter.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no previously-included files matching '*' found under directory 'test'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
            "  running build_ext\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "  building 'torch_scatter._version_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.8\n",
            "  creating build/temp.linux-x86_64-3.8/csrc\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/version.cpp -o build/temp.linux-x86_64-3.8/csrc/version.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_version_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/version.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_scatter/_version_cpu.so -s\n",
            "  building 'torch_scatter._version_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/version.cpp -o build/temp.linux-x86_64-3.8/csrc/version.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_version_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/version.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_scatter/_version_cuda.so -s\n",
            "  building 'torch_scatter._segment_csr_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.8/csrc/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/segment_csr.cpp -o build/temp.linux-x86_64-3.8/csrc/segment_csr.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_segment_csr_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/segment_csr_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/segment_csr_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_segment_csr_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/segment_csr.o build/temp.linux-x86_64-3.8/csrc/cpu/segment_csr_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_scatter/_segment_csr_cpu.so -s\n",
            "  building 'torch_scatter._segment_csr_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.8/csrc/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/segment_csr.cpp -o build/temp.linux-x86_64-3.8/csrc/segment_csr.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_segment_csr_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/segment_csr_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/segment_csr_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_segment_csr_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/segment_csr_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/segment_csr_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --expt-relaxed-constexpr -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_segment_csr_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/segment_csr.o build/temp.linux-x86_64-3.8/csrc/cpu/segment_csr_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/segment_csr_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_scatter/_segment_csr_cuda.so -s\n",
            "  building 'torch_scatter._scatter_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/scatter.cpp -o build/temp.linux-x86_64-3.8/csrc/scatter.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/scatter_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/scatter_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/scatter.o build/temp.linux-x86_64-3.8/csrc/cpu/scatter_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_scatter/_scatter_cpu.so -s\n",
            "  building 'torch_scatter._scatter_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/scatter.cpp -o build/temp.linux-x86_64-3.8/csrc/scatter.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_scatter_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/scatter_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/scatter_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_scatter_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/scatter_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/scatter_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --expt-relaxed-constexpr -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_scatter_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/scatter.o build/temp.linux-x86_64-3.8/csrc/cpu/scatter_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/scatter_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_scatter/_scatter_cuda.so -s\n",
            "  building 'torch_scatter._segment_coo_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/segment_coo.cpp -o build/temp.linux-x86_64-3.8/csrc/segment_coo.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_segment_coo_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/segment_coo_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/segment_coo_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_segment_coo_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/segment_coo.o build/temp.linux-x86_64-3.8/csrc/cpu/segment_coo_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_scatter/_segment_coo_cpu.so -s\n",
            "  building 'torch_scatter._segment_coo_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/segment_coo.cpp -o build/temp.linux-x86_64-3.8/csrc/segment_coo.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_segment_coo_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/segment_coo_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/segment_coo_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_segment_coo_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/segment_coo_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/segment_coo_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --expt-relaxed-constexpr -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_segment_coo_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/segment_coo.o build/temp.linux-x86_64-3.8/csrc/cpu/segment_coo_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/segment_coo_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_scatter/_segment_coo_cuda.so -s\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/__init__.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/_version_cpu.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/utils.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/segment_csr.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/placeholder.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/_scatter_cuda.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/_segment_csr_cuda.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter/composite\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/composite/__init__.py -> build/bdist.linux-x86_64/wheel/torch_scatter/composite\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/composite/logsumexp.py -> build/bdist.linux-x86_64/wheel/torch_scatter/composite\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/composite/softmax.py -> build/bdist.linux-x86_64/wheel/torch_scatter/composite\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/composite/std.py -> build/bdist.linux-x86_64/wheel/torch_scatter/composite\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/_version_cuda.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/_segment_coo_cpu.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/_scatter_cpu.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/scatter.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/_segment_coo_cuda.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/_segment_csr_cpu.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.8/torch_scatter/segment_coo.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  running install_egg_info\n",
            "  Copying torch_scatter.egg-info to build/bdist.linux-x86_64/wheel/torch_scatter-2.1.0-py3.8.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter-2.1.0.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-g0g5z21q/torch_scatter-2.1.0-cp38-cp38-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'torch_scatter/__init__.py'\n",
            "  adding 'torch_scatter/_scatter_cpu.so'\n",
            "  adding 'torch_scatter/_scatter_cuda.so'\n",
            "  adding 'torch_scatter/_segment_coo_cpu.so'\n",
            "  adding 'torch_scatter/_segment_coo_cuda.so'\n",
            "  adding 'torch_scatter/_segment_csr_cpu.so'\n",
            "  adding 'torch_scatter/_segment_csr_cuda.so'\n",
            "  adding 'torch_scatter/_version_cpu.so'\n",
            "  adding 'torch_scatter/_version_cuda.so'\n",
            "  adding 'torch_scatter/placeholder.py'\n",
            "  adding 'torch_scatter/scatter.py'\n",
            "  adding 'torch_scatter/segment_coo.py'\n",
            "  adding 'torch_scatter/segment_csr.py'\n",
            "  adding 'torch_scatter/utils.py'\n",
            "  adding 'torch_scatter/composite/__init__.py'\n",
            "  adding 'torch_scatter/composite/logsumexp.py'\n",
            "  adding 'torch_scatter/composite/softmax.py'\n",
            "  adding 'torch_scatter/composite/std.py'\n",
            "  adding 'torch_scatter-2.1.0.dist-info/LICENSE'\n",
            "  adding 'torch_scatter-2.1.0.dist-info/METADATA'\n",
            "  adding 'torch_scatter-2.1.0.dist-info/WHEEL'\n",
            "  adding 'torch_scatter-2.1.0.dist-info/top_level.txt'\n",
            "  adding 'torch_scatter-2.1.0.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.0-cp38-cp38-linux_x86_64.whl size=3401593 sha256=1b3fbac78ec2f3d8cb41dcc3506952a97ef09f4e43e549d39735218e88bc3ecd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f0pioip1/wheels/41/7f/4f/cf072bea3b6efe4561de2db3603ebbd8718c134c24caab8281\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0\n",
            "Using pip 22.0.4 from /usr/local/lib/python3.8/dist-packages/pip (python 3.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.16.tar.gz (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-ivnft890/torch_sparse.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-ivnft890/torch_sparse.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-ivnft890/torch_sparse.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-ivnft890/torch_sparse.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-ivnft890/torch_sparse.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-ivnft890/torch_sparse.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-ivnft890/torch_sparse.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/css'\n",
            "  warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/html'\n",
            "  warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/tests'\n",
            "  warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/examples'\n",
            "  warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/benchmark'\n",
            "  warning: no previously-included files matching '*' found under directory 'test'\n",
            "  warning: no previously-included files matching '*' found under directory 'benchmark'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-ivnft890/torch_sparse.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Running command python setup.py bdist_wheel\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  Generating grammar tables from /usr/lib/python3.8/lib2to3/Grammar.txt\n",
            "  Generating grammar tables from /usr/lib/python3.8/lib2to3/PatternGrammar.txt\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.8\n",
            "  creating build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/__init__.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/convert.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/spmm.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/utils.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/rw.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/add.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/select.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/transpose.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/tensor.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/reduce.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/index_select.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/metis.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/bandwidth.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/diag.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/sample.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/storage.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/matmul.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/saint.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/cat.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/spadd.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/mul.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/narrow.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/permute.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/testing.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/masked_select.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  copying torch_sparse/eye.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
            "  running egg_info\n",
            "  writing torch_sparse.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
            "  writing requirements to torch_sparse.egg-info/requires.txt\n",
            "  writing top-level names to torch_sparse.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/css'\n",
            "  warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/html'\n",
            "  warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/tests'\n",
            "  warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/examples'\n",
            "  warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/benchmark'\n",
            "  warning: no previously-included files matching '*' found under directory 'test'\n",
            "  warning: no previously-included files matching '*' found under directory 'benchmark'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
            "  running build_ext\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "  building 'torch_sparse._ego_sample_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.8\n",
            "  creating build/temp.linux-x86_64-3.8/csrc\n",
            "  creating build/temp.linux-x86_64-3.8/csrc/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/ego_sample.cpp -o build/temp.linux-x86_64-3.8/csrc/ego_sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_ego_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/ego_sample_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/ego_sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_ego_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/ego_sample.o build/temp.linux-x86_64-3.8/csrc/cpu/ego_sample_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_ego_sample_cpu.so -s\n",
            "  building 'torch_sparse._ego_sample_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/ego_sample.cpp -o build/temp.linux-x86_64-3.8/csrc/ego_sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_ego_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/ego_sample_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/ego_sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_ego_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/ego_sample.o build/temp.linux-x86_64-3.8/csrc/cpu/ego_sample_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_ego_sample_cuda.so -s\n",
            "  building 'torch_sparse._convert_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/convert.cpp -o build/temp.linux-x86_64-3.8/csrc/convert.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_convert_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/convert_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/convert_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_convert_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/convert.o build/temp.linux-x86_64-3.8/csrc/cpu/convert_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_convert_cpu.so -s\n",
            "  building 'torch_sparse._convert_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.8/csrc/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/convert.cpp -o build/temp.linux-x86_64-3.8/csrc/convert.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_convert_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/convert_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/convert_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_convert_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/convert_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/convert_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --expt-relaxed-constexpr -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_convert_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/convert.o build/temp.linux-x86_64-3.8/csrc/cpu/convert_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/convert_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_convert_cuda.so -s\n",
            "  building 'torch_sparse._version_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/version.cpp -o build/temp.linux-x86_64-3.8/csrc/version.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_version_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/version.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_version_cpu.so -s\n",
            "  building 'torch_sparse._version_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/version.cpp -o build/temp.linux-x86_64-3.8/csrc/version.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_version_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/version.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_version_cuda.so -s\n",
            "  building 'torch_sparse._sample_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/sample.cpp -o build/temp.linux-x86_64-3.8/csrc/sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/sample_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/sample.o build/temp.linux-x86_64-3.8/csrc/cpu/sample_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_sample_cpu.so -s\n",
            "  building 'torch_sparse._sample_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/sample.cpp -o build/temp.linux-x86_64-3.8/csrc/sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/sample_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/sample.o build/temp.linux-x86_64-3.8/csrc/cpu/sample_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_sample_cuda.so -s\n",
            "  building 'torch_sparse._hgt_sample_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/hgt_sample.cpp -o build/temp.linux-x86_64-3.8/csrc/hgt_sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_hgt_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/hgt_sample_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/hgt_sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_hgt_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/hgt_sample.o build/temp.linux-x86_64-3.8/csrc/cpu/hgt_sample_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_hgt_sample_cpu.so -s\n",
            "  building 'torch_sparse._hgt_sample_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/hgt_sample.cpp -o build/temp.linux-x86_64-3.8/csrc/hgt_sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_hgt_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/hgt_sample_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/hgt_sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_hgt_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/hgt_sample.o build/temp.linux-x86_64-3.8/csrc/cpu/hgt_sample_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_hgt_sample_cuda.so -s\n",
            "  building 'torch_sparse._diag_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/diag.cpp -o build/temp.linux-x86_64-3.8/csrc/diag.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_diag_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/diag_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/diag_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_diag_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/diag.o build/temp.linux-x86_64-3.8/csrc/cpu/diag_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_diag_cpu.so -s\n",
            "  building 'torch_sparse._diag_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/diag.cpp -o build/temp.linux-x86_64-3.8/csrc/diag.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_diag_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/diag_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/diag_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_diag_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/diag_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/diag_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --expt-relaxed-constexpr -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_diag_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/diag.o build/temp.linux-x86_64-3.8/csrc/cpu/diag_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/diag_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_diag_cuda.so -s\n",
            "  building 'torch_sparse._spmm_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/spmm.cpp -o build/temp.linux-x86_64-3.8/csrc/spmm.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_spmm_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/spmm_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/spmm_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_spmm_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/spmm.o build/temp.linux-x86_64-3.8/csrc/cpu/spmm_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_spmm_cpu.so -s\n",
            "  building 'torch_sparse._spmm_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/spmm.cpp -o build/temp.linux-x86_64-3.8/csrc/spmm.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_spmm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/spmm_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/spmm_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_spmm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/spmm_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/spmm_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --expt-relaxed-constexpr -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_spmm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/spmm.o build/temp.linux-x86_64-3.8/csrc/cpu/spmm_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/spmm_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_spmm_cuda.so -s\n",
            "  building 'torch_sparse._neighbor_sample_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/neighbor_sample.cpp -o build/temp.linux-x86_64-3.8/csrc/neighbor_sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_neighbor_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/neighbor_sample_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/neighbor_sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_neighbor_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/neighbor_sample.o build/temp.linux-x86_64-3.8/csrc/cpu/neighbor_sample_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_neighbor_sample_cpu.so -s\n",
            "  building 'torch_sparse._neighbor_sample_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/neighbor_sample.cpp -o build/temp.linux-x86_64-3.8/csrc/neighbor_sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_neighbor_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/neighbor_sample_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/neighbor_sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_neighbor_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/neighbor_sample.o build/temp.linux-x86_64-3.8/csrc/cpu/neighbor_sample_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_neighbor_sample_cuda.so -s\n",
            "  building 'torch_sparse._rw_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/rw.cpp -o build/temp.linux-x86_64-3.8/csrc/rw.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_rw_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/rw_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/rw_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_rw_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/rw.o build/temp.linux-x86_64-3.8/csrc/cpu/rw_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_rw_cpu.so -s\n",
            "  building 'torch_sparse._rw_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/rw.cpp -o build/temp.linux-x86_64-3.8/csrc/rw.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/rw_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/rw_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/rw_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/rw_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --expt-relaxed-constexpr -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/rw.o build/temp.linux-x86_64-3.8/csrc/cpu/rw_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/rw_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_rw_cuda.so -s\n",
            "  building 'torch_sparse._saint_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/saint.cpp -o build/temp.linux-x86_64-3.8/csrc/saint.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_saint_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/saint_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/saint_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_saint_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/saint.o build/temp.linux-x86_64-3.8/csrc/cpu/saint_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_saint_cpu.so -s\n",
            "  building 'torch_sparse._saint_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/saint.cpp -o build/temp.linux-x86_64-3.8/csrc/saint.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_saint_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/saint_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/saint_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_saint_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/saint.o build/temp.linux-x86_64-3.8/csrc/cpu/saint_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_saint_cuda.so -s\n",
            "  building 'torch_sparse._metis_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/metis.cpp -o build/temp.linux-x86_64-3.8/csrc/metis.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_metis_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/metis_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/metis_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_metis_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/metis.o build/temp.linux-x86_64-3.8/csrc/cpu/metis_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_metis_cpu.so -s\n",
            "  building 'torch_sparse._metis_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/metis.cpp -o build/temp.linux-x86_64-3.8/csrc/metis.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_metis_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/metis_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/metis_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_metis_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/metis.o build/temp.linux-x86_64-3.8/csrc/cpu/metis_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_metis_cuda.so -s\n",
            "  building 'torch_sparse._relabel_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/relabel.cpp -o build/temp.linux-x86_64-3.8/csrc/relabel.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_relabel_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/relabel_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/relabel_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_relabel_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/relabel.o build/temp.linux-x86_64-3.8/csrc/cpu/relabel_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_relabel_cpu.so -s\n",
            "  building 'torch_sparse._relabel_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/relabel.cpp -o build/temp.linux-x86_64-3.8/csrc/relabel.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_relabel_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -Ithird_party/parallel-hashmap -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/relabel_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/relabel_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_relabel_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/relabel.o build/temp.linux-x86_64-3.8/csrc/cpu/relabel_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_sparse/_relabel_cuda.so -s\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_diag_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_ego_sample_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/__init__.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_version_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/convert.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_rw_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/spmm.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/utils.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_sample_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_neighbor_sample_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_hgt_sample_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/rw.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_saint_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/add.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_ego_sample_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_neighbor_sample_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_spmm_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_convert_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/select.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/transpose.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/tensor.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_convert_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/reduce.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_saint_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/index_select.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/metis.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_spmm_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/bandwidth.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/diag.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_version_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_rw_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_diag_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/sample.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/storage.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_relabel_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_hgt_sample_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/matmul.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/spspmm.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_metis_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/saint.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/cat.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/spadd.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/mul.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/narrow.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/permute.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_sample_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/testing.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/masked_select.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/coalesce.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/eye.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_relabel_cuda.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.8/torch_sparse/_metis_cpu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  running install_egg_info\n",
            "  Copying torch_sparse.egg-info to build/bdist.linux-x86_64/wheel/torch_sparse-0.6.16-py3.8.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_sparse-0.6.16.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-52c9hmy4/torch_sparse-0.6.16-cp38-cp38-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'torch_sparse/__init__.py'\n",
            "  adding 'torch_sparse/_convert_cpu.so'\n",
            "  adding 'torch_sparse/_convert_cuda.so'\n",
            "  adding 'torch_sparse/_diag_cpu.so'\n",
            "  adding 'torch_sparse/_diag_cuda.so'\n",
            "  adding 'torch_sparse/_ego_sample_cpu.so'\n",
            "  adding 'torch_sparse/_ego_sample_cuda.so'\n",
            "  adding 'torch_sparse/_hgt_sample_cpu.so'\n",
            "  adding 'torch_sparse/_hgt_sample_cuda.so'\n",
            "  adding 'torch_sparse/_metis_cpu.so'\n",
            "  adding 'torch_sparse/_metis_cuda.so'\n",
            "  adding 'torch_sparse/_neighbor_sample_cpu.so'\n",
            "  adding 'torch_sparse/_neighbor_sample_cuda.so'\n",
            "  adding 'torch_sparse/_relabel_cpu.so'\n",
            "  adding 'torch_sparse/_relabel_cuda.so'\n",
            "  adding 'torch_sparse/_rw_cpu.so'\n",
            "  adding 'torch_sparse/_rw_cuda.so'\n",
            "  adding 'torch_sparse/_saint_cpu.so'\n",
            "  adding 'torch_sparse/_saint_cuda.so'\n",
            "  adding 'torch_sparse/_sample_cpu.so'\n",
            "  adding 'torch_sparse/_sample_cuda.so'\n",
            "  adding 'torch_sparse/_spmm_cpu.so'\n",
            "  adding 'torch_sparse/_spmm_cuda.so'\n",
            "  adding 'torch_sparse/_version_cpu.so'\n",
            "  adding 'torch_sparse/_version_cuda.so'\n",
            "  adding 'torch_sparse/add.py'\n",
            "  adding 'torch_sparse/bandwidth.py'\n",
            "  adding 'torch_sparse/cat.py'\n",
            "  adding 'torch_sparse/coalesce.py'\n",
            "  adding 'torch_sparse/convert.py'\n",
            "  adding 'torch_sparse/diag.py'\n",
            "  adding 'torch_sparse/eye.py'\n",
            "  adding 'torch_sparse/index_select.py'\n",
            "  adding 'torch_sparse/masked_select.py'\n",
            "  adding 'torch_sparse/matmul.py'\n",
            "  adding 'torch_sparse/metis.py'\n",
            "  adding 'torch_sparse/mul.py'\n",
            "  adding 'torch_sparse/narrow.py'\n",
            "  adding 'torch_sparse/permute.py'\n",
            "  adding 'torch_sparse/reduce.py'\n",
            "  adding 'torch_sparse/rw.py'\n",
            "  adding 'torch_sparse/saint.py'\n",
            "  adding 'torch_sparse/sample.py'\n",
            "  adding 'torch_sparse/select.py'\n",
            "  adding 'torch_sparse/spadd.py'\n",
            "  adding 'torch_sparse/spmm.py'\n",
            "  adding 'torch_sparse/spspmm.py'\n",
            "  adding 'torch_sparse/storage.py'\n",
            "  adding 'torch_sparse/tensor.py'\n",
            "  adding 'torch_sparse/testing.py'\n",
            "  adding 'torch_sparse/transpose.py'\n",
            "  adding 'torch_sparse/utils.py'\n",
            "  adding 'torch_sparse-0.6.16.dist-info/LICENSE'\n",
            "  adding 'torch_sparse-0.6.16.dist-info/METADATA'\n",
            "  adding 'torch_sparse-0.6.16.dist-info/WHEEL'\n",
            "  adding 'torch_sparse-0.6.16.dist-info/top_level.txt'\n",
            "  adding 'torch_sparse-0.6.16.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.16-cp38-cp38-linux_x86_64.whl size=2694259 sha256=0c6150db7219c67691faeca3b5c817c2d10c485b83f8b45899b906ceca5cd97d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yd57nl0n/wheels/d7/f5/41/86610d3a3ce0bec241d8549ecdd6c7e07fe000e041616cfcd6\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.16\n",
            "Using pip 22.0.4 from /usr/local/lib/python3.8/dist-packages/pip (python 3.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.0.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 KB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-n6axpwne/torch_cluster.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-n6axpwne/torch_cluster.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-n6axpwne/torch_cluster.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-n6axpwne/torch_cluster.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-n6axpwne/torch_cluster.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-n6axpwne/torch_cluster.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-n6axpwne/torch_cluster.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no previously-included files matching '*' found under directory 'test'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-n6axpwne/torch_cluster.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Running command python setup.py bdist_wheel\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  Generating grammar tables from /usr/lib/python3.8/lib2to3/Grammar.txt\n",
            "  Generating grammar tables from /usr/lib/python3.8/lib2to3/PatternGrammar.txt\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.8\n",
            "  creating build/lib.linux-x86_64-3.8/torch_cluster\n",
            "  copying torch_cluster/__init__.py -> build/lib.linux-x86_64-3.8/torch_cluster\n",
            "  copying torch_cluster/rw.py -> build/lib.linux-x86_64-3.8/torch_cluster\n",
            "  copying torch_cluster/sampler.py -> build/lib.linux-x86_64-3.8/torch_cluster\n",
            "  copying torch_cluster/nearest.py -> build/lib.linux-x86_64-3.8/torch_cluster\n",
            "  copying torch_cluster/grid.py -> build/lib.linux-x86_64-3.8/torch_cluster\n",
            "  copying torch_cluster/graclus.py -> build/lib.linux-x86_64-3.8/torch_cluster\n",
            "  copying torch_cluster/radius.py -> build/lib.linux-x86_64-3.8/torch_cluster\n",
            "  copying torch_cluster/knn.py -> build/lib.linux-x86_64-3.8/torch_cluster\n",
            "  copying torch_cluster/fps.py -> build/lib.linux-x86_64-3.8/torch_cluster\n",
            "  running egg_info\n",
            "  writing torch_cluster.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_cluster.egg-info/dependency_links.txt\n",
            "  writing requirements to torch_cluster.egg-info/requires.txt\n",
            "  writing top-level names to torch_cluster.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_cluster.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no previously-included files matching '*' found under directory 'test'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'torch_cluster.egg-info/SOURCES.txt'\n",
            "  running build_ext\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "  building 'torch_cluster._sampler_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.8\n",
            "  creating build/temp.linux-x86_64-3.8/csrc\n",
            "  creating build/temp.linux-x86_64-3.8/csrc/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/sampler.cpp -o build/temp.linux-x86_64-3.8/csrc/sampler.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_sampler_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/sampler_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/sampler_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_sampler_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/sampler.o build/temp.linux-x86_64-3.8/csrc/cpu/sampler_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_cluster/_sampler_cpu.so -s\n",
            "  building 'torch_cluster._sampler_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/sampler.cpp -o build/temp.linux-x86_64-3.8/csrc/sampler.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_sampler_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/sampler_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/sampler_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_sampler_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/sampler.o build/temp.linux-x86_64-3.8/csrc/cpu/sampler_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_cluster/_sampler_cuda.so -s\n",
            "  building 'torch_cluster._nearest_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/nearest.cpp -o build/temp.linux-x86_64-3.8/csrc/nearest.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_nearest_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/nearest.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_cluster/_nearest_cpu.so -s\n",
            "  building 'torch_cluster._nearest_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.8/csrc/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/nearest.cpp -o build/temp.linux-x86_64-3.8/csrc/nearest.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_nearest_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/nearest_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/nearest_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-relaxed-constexpr -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_nearest_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/nearest.o build/temp.linux-x86_64-3.8/csrc/cuda/nearest_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_cluster/_nearest_cuda.so -s\n",
            "  building 'torch_cluster._version_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/version.cpp -o build/temp.linux-x86_64-3.8/csrc/version.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_version_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/version.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_cluster/_version_cpu.so -s\n",
            "  building 'torch_cluster._version_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/version.cpp -o build/temp.linux-x86_64-3.8/csrc/version.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_version_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/version.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_cluster/_version_cuda.so -s\n",
            "  building 'torch_cluster._fps_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/fps.cpp -o build/temp.linux-x86_64-3.8/csrc/fps.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_fps_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/fps_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/fps_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_fps_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/fps.o build/temp.linux-x86_64-3.8/csrc/cpu/fps_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_cluster/_fps_cpu.so -s\n",
            "  building 'torch_cluster._fps_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/fps.cpp -o build/temp.linux-x86_64-3.8/csrc/fps.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_fps_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/fps_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/fps_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_fps_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/fps_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/fps_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-relaxed-constexpr -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_fps_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/fps.o build/temp.linux-x86_64-3.8/csrc/cpu/fps_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/fps_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_cluster/_fps_cuda.so -s\n",
            "  building 'torch_cluster._knn_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/knn.cpp -o build/temp.linux-x86_64-3.8/csrc/knn.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_knn_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/knn_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/knn_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_knn_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/knn.o build/temp.linux-x86_64-3.8/csrc/cpu/knn_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_cluster/_knn_cpu.so -s\n",
            "  building 'torch_cluster._knn_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/knn.cpp -o build/temp.linux-x86_64-3.8/csrc/knn.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_knn_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/knn_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/knn_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_knn_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/knn_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/knn_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-relaxed-constexpr -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_knn_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/knn.o build/temp.linux-x86_64-3.8/csrc/cpu/knn_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/knn_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_cluster/_knn_cuda.so -s\n",
            "  building 'torch_cluster._graclus_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/graclus.cpp -o build/temp.linux-x86_64-3.8/csrc/graclus.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_graclus_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/graclus_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/graclus_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_graclus_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/graclus.o build/temp.linux-x86_64-3.8/csrc/cpu/graclus_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_cluster/_graclus_cpu.so -s\n",
            "  building 'torch_cluster._graclus_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/graclus.cpp -o build/temp.linux-x86_64-3.8/csrc/graclus.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_graclus_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/graclus_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/graclus_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_graclus_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/graclus_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/graclus_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-relaxed-constexpr -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_graclus_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/graclus.o build/temp.linux-x86_64-3.8/csrc/cpu/graclus_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/graclus_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_cluster/_graclus_cuda.so -s\n",
            "  building 'torch_cluster._grid_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/grid.cpp -o build/temp.linux-x86_64-3.8/csrc/grid.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_grid_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/grid_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/grid_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_grid_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/grid.o build/temp.linux-x86_64-3.8/csrc/cpu/grid_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_cluster/_grid_cpu.so -s\n",
            "  building 'torch_cluster._grid_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/grid.cpp -o build/temp.linux-x86_64-3.8/csrc/grid.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_grid_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/grid_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/grid_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_grid_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/grid_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/grid_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-relaxed-constexpr -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_grid_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/grid.o build/temp.linux-x86_64-3.8/csrc/cpu/grid_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/grid_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_cluster/_grid_cuda.so -s\n",
            "  building 'torch_cluster._rw_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/rw.cpp -o build/temp.linux-x86_64-3.8/csrc/rw.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_rw_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/rw_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/rw_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_rw_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/rw.o build/temp.linux-x86_64-3.8/csrc/cpu/rw_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_cluster/_rw_cpu.so -s\n",
            "  building 'torch_cluster._rw_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/rw.cpp -o build/temp.linux-x86_64-3.8/csrc/rw.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/rw_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/rw_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/rw_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/rw_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-relaxed-constexpr -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/rw.o build/temp.linux-x86_64-3.8/csrc/cpu/rw_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/rw_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_cluster/_rw_cuda.so -s\n",
            "  building 'torch_cluster._radius_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/radius.cpp -o build/temp.linux-x86_64-3.8/csrc/radius.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_radius_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c csrc/cpu/radius_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/radius_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_radius_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/radius.o build/temp.linux-x86_64-3.8/csrc/cpu/radius_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_cluster/_radius_cpu.so -s\n",
            "  building 'torch_cluster._radius_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/radius.cpp -o build/temp.linux-x86_64-3.8/csrc/radius.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_radius_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cpu/radius_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/radius_cpu.o -O2 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_radius_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c csrc/cuda/radius_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/radius_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-relaxed-constexpr -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_radius_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/csrc/radius.o build/temp.linux-x86_64-3.8/csrc/cpu/radius_cpu.o build/temp.linux-x86_64-3.8/csrc/cuda/radius_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_cluster/_radius_cuda.so -s\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_nearest_cuda.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/__init__.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_version_cpu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_rw_cuda.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_graclus_cuda.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_fps_cpu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/rw.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/sampler.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_grid_cuda.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_sampler_cuda.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/nearest.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/grid.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_version_cuda.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_rw_cpu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_graclus_cpu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_grid_cpu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_knn_cuda.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_sampler_cpu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/graclus.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_nearest_cpu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_knn_cpu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_fps_cuda.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_radius_cuda.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/radius.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/_radius_cpu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/knn.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.8/torch_cluster/fps.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  running install_egg_info\n",
            "  Copying torch_cluster.egg-info to build/bdist.linux-x86_64/wheel/torch_cluster-1.6.0-py3.8.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_cluster-1.6.0.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-75x6nono/torch_cluster-1.6.0-cp38-cp38-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'torch_cluster/__init__.py'\n",
            "  adding 'torch_cluster/_fps_cpu.so'\n",
            "  adding 'torch_cluster/_fps_cuda.so'\n",
            "  adding 'torch_cluster/_graclus_cpu.so'\n",
            "  adding 'torch_cluster/_graclus_cuda.so'\n",
            "  adding 'torch_cluster/_grid_cpu.so'\n",
            "  adding 'torch_cluster/_grid_cuda.so'\n",
            "  adding 'torch_cluster/_knn_cpu.so'\n",
            "  adding 'torch_cluster/_knn_cuda.so'\n",
            "  adding 'torch_cluster/_nearest_cpu.so'\n",
            "  adding 'torch_cluster/_nearest_cuda.so'\n",
            "  adding 'torch_cluster/_radius_cpu.so'\n",
            "  adding 'torch_cluster/_radius_cuda.so'\n",
            "  adding 'torch_cluster/_rw_cpu.so'\n",
            "  adding 'torch_cluster/_rw_cuda.so'\n",
            "  adding 'torch_cluster/_sampler_cpu.so'\n",
            "  adding 'torch_cluster/_sampler_cuda.so'\n",
            "  adding 'torch_cluster/_version_cpu.so'\n",
            "  adding 'torch_cluster/_version_cuda.so'\n",
            "  adding 'torch_cluster/fps.py'\n",
            "  adding 'torch_cluster/graclus.py'\n",
            "  adding 'torch_cluster/grid.py'\n",
            "  adding 'torch_cluster/knn.py'\n",
            "  adding 'torch_cluster/nearest.py'\n",
            "  adding 'torch_cluster/radius.py'\n",
            "  adding 'torch_cluster/rw.py'\n",
            "  adding 'torch_cluster/sampler.py'\n",
            "  adding 'torch_cluster-1.6.0.dist-info/LICENSE'\n",
            "  adding 'torch_cluster-1.6.0.dist-info/METADATA'\n",
            "  adding 'torch_cluster-1.6.0.dist-info/WHEEL'\n",
            "  adding 'torch_cluster-1.6.0.dist-info/top_level.txt'\n",
            "  adding 'torch_cluster-1.6.0.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.0-cp38-cp38-linux_x86_64.whl size=1917838 sha256=67f811a7d7f15a66eba69fec876c272487ad438d29eb194b6721090404a40298\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d4_zvc0u/wheels/35/db/1e/373df9dd7d703433fe3b1bd6e8ef628b2cff9fe885ce3b6034\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Using pip 22.0.4 from /usr/local/lib/python3.8/dist-packages/pip (python 3.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-spline-conv\n",
            "  Downloading torch_spline_conv-1.2.1.tar.gz (13 kB)\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-lisb_jnv/torch_spline_conv.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-lisb_jnv/torch_spline_conv.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-lisb_jnv/torch_spline_conv.egg-info/dependency_links.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-lisb_jnv/torch_spline_conv.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-lisb_jnv/torch_spline_conv.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-lisb_jnv/torch_spline_conv.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "    warnings.warn(msg.format('we could not find ninja.'))\n",
            "  warning: no previously-included files matching '*' found under directory 'test'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-lisb_jnv/torch_spline_conv.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-spline-conv\n",
            "  Running command python setup.py bdist_wheel\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  /usr/local/lib/python3.8/dist-packages/setuptools/dist.py:697: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "    warnings.warn(\n",
            "  running bdist_wheel\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "    warnings.warn(msg.format('we could not find ninja.'))\n",
            "  running build\n",
            "  running build_py\n",
            "  Generating grammar tables from /usr/lib/python3.8/lib2to3/Grammar.txt\n",
            "  Generating grammar tables from /usr/lib/python3.8/lib2to3/PatternGrammar.txt\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.8\n",
            "  creating build/lib.linux-x86_64-3.8/torch_spline_conv\n",
            "  copying torch_spline_conv/__init__.py -> build/lib.linux-x86_64-3.8/torch_spline_conv\n",
            "  copying torch_spline_conv/weighting.py -> build/lib.linux-x86_64-3.8/torch_spline_conv\n",
            "  copying torch_spline_conv/conv.py -> build/lib.linux-x86_64-3.8/torch_spline_conv\n",
            "  copying torch_spline_conv/basis.py -> build/lib.linux-x86_64-3.8/torch_spline_conv\n",
            "  running build_ext\n",
            "  /usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "  building 'torch_spline_conv._weighting_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.8\n",
            "  creating build/temp.linux-x86_64-3.8/tmp\n",
            "  creating build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje\n",
            "  creating build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa\n",
            "  creating build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc\n",
            "  creating build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/weighting.cpp -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/weighting.o -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_weighting_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/weighting_cpu.cpp -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/weighting_cpu.o -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_weighting_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/weighting.o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/weighting_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_spline_conv/_weighting_cpu.so -s\n",
            "  building 'torch_spline_conv._weighting_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/weighting.cpp -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/weighting.o -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_weighting_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/weighting_cpu.cpp -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/weighting_cpu.o -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_weighting_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_CUDA -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cuda/weighting_cuda.cu -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cuda/weighting_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -arch=sm_35 --expt-relaxed-constexpr -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_weighting_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/weighting.o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/weighting_cpu.o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cuda/weighting_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_spline_conv/_weighting_cuda.so -s\n",
            "  building 'torch_spline_conv._basis_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/basis.cpp -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/basis.o -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_basis_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/basis_cpu.cpp -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/basis_cpu.o -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_basis_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/basis.o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/basis_cpu.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_spline_conv/_basis_cpu.so -s\n",
            "  building 'torch_spline_conv._basis_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/basis.cpp -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/basis.o -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_basis_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/basis_cpu.cpp -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/basis_cpu.o -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_basis_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  /usr/local/cuda/bin/nvcc -DWITH_CUDA -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cuda/basis_cuda.cu -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cuda/basis_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -arch=sm_35 --expt-relaxed-constexpr -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_basis_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/basis.o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cpu/basis_cpu.o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/cuda/basis_cuda.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_spline_conv/_basis_cuda.so -s\n",
            "  building 'torch_spline_conv._version_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/version.cpp -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/version.o -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_version_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/version.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_spline_conv/_version_cpu.so -s\n",
            "  building 'torch_spline_conv._version_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/version.cpp -o build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/version.o -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_version_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/tmp/pip-install-9av0voje/torch-spline-conv_5b1fce8dfbb54534bee88b2bd30acbfa/csrc/version.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.8/torch_spline_conv/_version_cuda.so -s\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.8/torch_spline_conv/_basis_cpu.so -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.8/torch_spline_conv/__init__.py -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.8/torch_spline_conv/_version_cpu.so -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.8/torch_spline_conv/_weighting_cpu.so -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.8/torch_spline_conv/_weighting_cuda.so -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.8/torch_spline_conv/_basis_cuda.so -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.8/torch_spline_conv/weighting.py -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.8/torch_spline_conv/conv.py -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.8/torch_spline_conv/_version_cuda.so -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.8/torch_spline_conv/basis.py -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing torch_spline_conv.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_spline_conv.egg-info/dependency_links.txt\n",
            "  writing top-level names to torch_spline_conv.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_spline_conv.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no previously-included files matching '*' found under directory 'test'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'torch_spline_conv.egg-info/SOURCES.txt'\n",
            "  Copying torch_spline_conv.egg-info to build/bdist.linux-x86_64/wheel/torch_spline_conv-1.2.1-py3.8.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_spline_conv-1.2.1.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-48514v1m/torch_spline_conv-1.2.1-cp38-cp38-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'torch_spline_conv/__init__.py'\n",
            "  adding 'torch_spline_conv/_basis_cpu.so'\n",
            "  adding 'torch_spline_conv/_basis_cuda.so'\n",
            "  adding 'torch_spline_conv/_version_cpu.so'\n",
            "  adding 'torch_spline_conv/_version_cuda.so'\n",
            "  adding 'torch_spline_conv/_weighting_cpu.so'\n",
            "  adding 'torch_spline_conv/_weighting_cuda.so'\n",
            "  adding 'torch_spline_conv/basis.py'\n",
            "  adding 'torch_spline_conv/conv.py'\n",
            "  adding 'torch_spline_conv/weighting.py'\n",
            "  adding 'torch_spline_conv-1.2.1.dist-info/LICENSE'\n",
            "  adding 'torch_spline_conv-1.2.1.dist-info/METADATA'\n",
            "  adding 'torch_spline_conv-1.2.1.dist-info/WHEEL'\n",
            "  adding 'torch_spline_conv-1.2.1.dist-info/top_level.txt'\n",
            "  adding 'torch_spline_conv-1.2.1.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.2.1-cp38-cp38-linux_x86_64.whl size=495649 sha256=1dc0a4e152709f952e316c1d0a326582efd5f054a0546f1b13d020436327208b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-etr24dfr/wheels/f1/34/51/03f6eead20780340a7f7a188f714b5872a0db06e5856dd1ad8\n",
            "Successfully built torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.2.1)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=af12a7c20f26f4ce76565c95a590168a67e80dea6810b58441982e7e513db8c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n",
            "--2023-02-07 07:53:23--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.202.168.65, 54.237.133.81, 54.161.241.46, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.202.168.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  13.9MB/s    in 0.9s    \n",
            "\n",
            "2023-02-07 07:53:24 (13.9 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "MRhL-M0Tyxqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the model\n",
        "\n",
        "The `GNNStack` is our general framework for a GNN which can handle different types of convolutional layers, and both node and graph classification. The `build_conv_model` method determines which type of convolutional layer to use for the given task - here we choose to use a graph convolutional network for node classification, and a graph isomorphism network for graph classification. Note that PyTorch Geometric provides out of the box modules for these layer, which we use here. The model consists of 2 layers of convolution, followed by mean pooling in the case of graph classification, followed by two fully-connected layers. Since our goal here is classification, we use a negative log-likelihood loss function."
      ],
      "metadata": {
        "id": "it6-HMdD2v8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNStack(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, task = 'node'):\n",
        "        super(GNNStack, self).__init__()\n",
        "        self.task = task\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
        "        self.lns = nn.ModuleList()\n",
        "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
        "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
        "\n",
        "        for l in range(2):\n",
        "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25),\n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "        if not (self.task == 'node' or self.task == 'graph'):\n",
        "            raise RuntimeError('Unknown task.')\n",
        "\n",
        "        self.dropout = 0.25\n",
        "        self.num_layers = 3\n",
        "\n",
        "    def build_conv_model(self, input_dim, hidden_dim):\n",
        "        # Refer to pytorch geometric nn module for different implementation of GNNs.\n",
        "        if self.task == 'node':\n",
        "            return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
        "        else:\n",
        "            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
        "                                                nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\n",
        "            \n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        if data.num_node_features == 0:\n",
        "            x = torch.ones(data.num_nodes, 1)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            emb = x\n",
        "            x = F.relu(x)\n",
        "            x = F.fropout(x, p = self.dropout, training = self.training)\n",
        "            if not i == self.num_layers - 1:\n",
        "                x = self.lns[i](x)\n",
        "\n",
        "        if self.task == 'graph':\n",
        "            x = pyg_nn.global_mean_pool(x, batch)\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "\n",
        "        return emb, F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)"
      ],
      "metadata": {
        "id": "pw4IefpJ2euB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here pyg_nn.GCNConv and pyg_nn.GINConv are instances of Message Passing. They define a single layer of graph convolution, which can be decompressed into:\n",
        "* Message computation\n",
        "* Aggregation \n",
        "* Update\n",
        "* Pooling\n",
        "\n",
        "Here, we give an example of how to subclass the pytorch geometric MessagePassing class to derive a new model (rather than using existing GCNConv and GINConv).\n",
        "\n",
        "We make use of `MessagePassing`'s key building blocks:\n",
        "* `aggr ='add'`: The aggregation method to use (\"add\", \"mean\" or \"max\").\n",
        "* `propagate()`: The initial call to start propagating messgaes. Takes in the edge indices and any other data to pass along (e.g. to update node embeddings).\n",
        "* `messgae()`: Constructs messages to node i. Takes any argument which was initially passed to propagate().\n",
        "* `update()`: Updates node embeddings. Takes in the output of aggregation as first argument and any argument which was initially passed to propagate().\n"
      ],
      "metadata": {
        "id": "QLMf4fih_QhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomConv(pyg_nn.MessagePassing):\n",
        "    def _init_(self, in_channels, out_channels):\n",
        "        super(CustomConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
        "        self.lin = nn.Linear(in_channels, out_channels)\n",
        "        self.lin_self = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "\n",
        "        # Add self-loops to the adjacency matrix.\n",
        "        edge_index, _ = pyg_utils.remove_self.loops(edge_index)\n",
        "\n",
        "        # Transform node feature matrix.\n",
        "        self_x = self.lin_self(x)\n",
        "        # x = self.lin(x)\n",
        "\n",
        "        return self_x + self.propagate(edge_index, size = (x.size(0), x.size(0)), x = self.lin(x))\n",
        "\n",
        "    def message(self, x_i, x_j, edge_index, size):\n",
        "        # Compute messages\n",
        "        # x_j has shape [E, out_channels]\n",
        "\n",
        "        row, col = edge_index\n",
        "        deg = pyg_utils.degree(row, size[0], dtype = x_j.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # aggr_out has shape [N, out_channels]\n",
        "        return aggr_out"
      ],
      "metadata": {
        "id": "rdbaGJMT_NxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training setup\n",
        "\n",
        "We train the model in a standard way here, running it forwards to compute its predicted label distribution and backpropagating the error. Note the task setup in our graph setting: for node classification, we define a subset of nodes to be training nodes and the rest of the nodes to be test nodes, and mask our the test nodes during training via `batch.train_mask`. For graph classification, we use 80% of the graphs for training and the remainder for testing, as in other classification settings."
      ],
      "metadata": {
        "id": "jf1p-C84GfBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, task, writer):\n",
        "    if task == 'graph':\n",
        "        data_size = len(dataset)\n",
        "        loader = DataLoader(dataset[:int(data_size * 0.8)], batch_size = 64, shuffle = True)\n",
        "        test_loader = DataLoader(dataset[int(data_size * 0.8):], batch_size = 64, shuffle = True)\n",
        "    else:\n",
        "        test_loader = loader = DataLoader(dataset, batch_size = 64, shuffle = True)\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(max(dataset.num_node_features, 1), 32, dataset.num_classes, task = task)\n",
        "    opt = optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "    # train\n",
        "    for epoch in range(200):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in loader:\n",
        "            # print(batch.train_mask, '____')\n",
        "            opt.zero_grad()\n",
        "            embedding, pred = model(batch)\n",
        "            label = batch.y\n",
        "\n",
        "        if task == 'node':\n",
        "             pred = pred[batch.train_mask]\n",
        "             label = label[batch.train_mask]\n",
        "\n",
        "        loss = model.loss(pred, label)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "        total_loss /= len(loader.dataset)\n",
        "        writer.add_scalar(\"loss\", total_loss, epoch)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            test_acc = test(test_loader, model)\n",
        "            print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(epoch, total_loss, test_acc))\n",
        "            writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "__6e_vc7GL_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test time, for the CiteSeer/Cora node classification task, there is only 1 graph. So we use masking to determine validation and test set. For graph classification tasks. a subset of graphs is considered validation / test graph."
      ],
      "metadata": {
        "id": "LVtl2rUckTdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(loader, model, is_validation = False):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        with torch.no_grad():\n",
        "            emb, pred = model(data)\n",
        "            pred = pred.argmax(dim = 1)\n",
        "            label = data.y\n",
        "\n",
        "        if model.task == 'node':\n",
        "            mask = data.val_mask if is_validation else data.test_mask\n",
        "            # node classification: only evaluate on nodes in test set\n",
        "            pred = pred[mask]\n",
        "\n",
        "        correct += pred.eg(label).sum().item()\n",
        "\n",
        "    if model.task == 'graph':\n",
        "        total = len(loader.dataset)\n",
        "    else:\n",
        "        total = 0\n",
        "        for data in loader.dataset:\n",
        "            total += torch.sum(data.test_mask).item()\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "G_g0EtCfjbmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model\n",
        "\n",
        "Let's train out model and visualize its progress. First, run this snippet to generate a link to TensorBoardX, which will take you to a page where you can visualize the loss and accuracy curves of the model."
      ],
      "metadata": {
        "id": "X9OxYNTFlsdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(\"./log\")\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s https://localhost:4040/api/tunnels | python3 -c \\\n",
        "\"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b2kZfXqlrYw",
        "outputId": "f322e86d-0de4-4b05-cc62-433fb63be6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.8/json/__init__.py\", line 293, in load\n",
            "    return loads(fp.read(),\n",
            "  File \"/usr/lib/python3.8/json/__init__.py\", line 357, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.8/json/decoder.py\", line 337, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now run this snippet to start the training. When it's finished, you should ne able to see its training and test performance over time on the TensorBoardX page. If you run the snippet multiple times, you will be able to see multiple training curves and compare them.\n",
        "\n",
        "We start with a graph classification task on the IMDB-BINARY dataset."
      ],
      "metadata": {
        "id": "APDPJxDLmgEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter(\"./log\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "dataset = TUDataset(root = '/tmp/ENZYMES', name = 'ENZYMES')\n",
        "dataset = dataset.shuffle()\n",
        "task = 'graph'\n",
        "\n",
        "model = train(dataset, task, writer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "A6K0D6oJmfYJ",
        "outputId": "2795ab29-2921-49bb-df81-88ef849ee40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
            "Extracting /tmp/ENZYMES/ENZYMES/ENZYMES.zip\n",
            "Processing...\n",
            "Done!\n",
            "/usr/local/lib/python3.8/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-440ddf42c432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'graph'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-d98779e0d231>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, task, writer)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# print(batch.train_mask, '____')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-9a4667719f80>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn.functional' has no attribute 'fropout'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we try a node classification task on the Citeseer citation network:"
      ],
      "metadata": {
        "id": "264MDLGCuduu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter(\"./log/\" + datetime.nw().strftime(\"%Y%m%d - %H%M%S\"))\n",
        "\n",
        "dataset = Planetoid(root = '/tmp/cora', name = 'cora')\n",
        "task = 'node'\n",
        "\n",
        "model = train(dataset, task , writer)"
      ],
      "metadata": {
        "id": "KF3oQETJuLJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing node embeddings\n",
        "\n",
        "One great quality about graph neural networks is that, like other deep methods, their hidden layers provide low-dimensional representations of our data. In the case of node classification, we get a low-dimensional representation for each node in our graph. Let's visualize the output of the last convolutional layer in our node classification GNN via TSNE, a method for plotting high-dimensional data. Nodes are colored according to their labels. We see that nodes with similar labels tend to be near each other in the embedding space, a good indication that our model has learned a useful representation."
      ],
      "metadata": {
        "id": "csEivsemu-xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "color_list = [\"red\", \"orange\", \"green\", \"blue\", \"purple\", \"brown\"]\n",
        "\n",
        "loader = DataLoader(dataset, batch_size = 64, shuffle = True)\n",
        "embs = []\n",
        "colors = []\n",
        "for batch in loader:\n",
        "    emb, pred = model(batch)\n",
        "    embs.append(emb)\n",
        "    colors += [color_list[y] for y in batch.y]\n",
        "embs = torch.cat(embs, dim = 0)\n",
        "xs, ys = zip(*TSNE().fit_transform(embs.detach().numpy()))\n",
        "plt.scatter(xs, ys, color = colors)"
      ],
      "metadata": {
        "id": "RMht1HRhu6MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning unsupervised embeddings with graph autoencoders\n",
        "\n",
        "Finally, GNNs fit nicely in the framework of other neural approaches, and can be used as part of autoencoder techniques, pretraining and multitask learning methods, etc. Here we explore the idea of neural network representations further by building a graph autoencoder which learns these representations in a completely unsupervised way. In contrast to the previous example, we do not make use of the given node labels when training this representation. Instead, we encode the nodes in our network in a low-dimensional space in such a way that the embeddings can be decoded into a reconstruction of the original network. We use graph convolutional layers in the encoder.\n",
        "\n",
        "You can again use TensorBoardX here to visualize the training progress."
      ],
      "metadata": {
        "id": "91rxigBewvRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(in_channels, 2 * out_channels, cached = True)\n",
        "        self.conv2 = pyg_nn.GCNConv(2 * out_channels, out_channels, cached = True)\n",
        "\n",
        "def forward(self, x, edge_index):\n",
        "    x = F.relu(self.conv1(x, edge_index))\n",
        "    return self.conv2(x, edge_index)\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(x, train_pos_edge_index)\n",
        "    loss = model.recon_loss(z, train_pos_edge_index)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    writer.add_scalar(\"loss\", loss.item(), epoch)\n",
        "\n",
        "def test(pos_edge_index, neg_edge_index):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        with torch.no_grad():\n",
        "            z = model.encode(x, train_pos_edge_index)\n",
        "        return model.test(z, pos_edge_index, neg_edge_index)\n",
        "\n",
        "writer = SummaryWriter(\"./log\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "dataset = Planetoid(\"/tmp/citeseer\", \"Citeseer\", T.NormalizeFeatures())\n",
        "data = dataset[0]\n",
        "\n",
        "channels = 16\n",
        "dev = torch.device('cuda' if torch.cude.is_available() else 'cpu')\n",
        "print('CUDA availability:', torch.cuda.is_available())\n",
        "\n",
        "# encoder: written by us; decoder: default (inner product)\n",
        "model = pyg_nn.GAE(Encoder(dataset.num_features, channels)).to(dev)\n",
        "labels = data.y\n",
        "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
        "data = model.split_edges(data)\n",
        "x, train_pos_edge_index = data.x.to(dev), data.train_pos_edge_index.to(dev)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    train(epoch)\n",
        "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
        "    writer.add_scalar(\"AUC\", auc, epoch)\n",
        "    writer.add_scarlar(\"AP\", ap, epoch)\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "1_0w7j-ixphJ",
        "outputId": "66ccf2e4-5ffc-4b6d-9b4e-4c89b2c90d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e1586eb3b11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./log\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlanetoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/citeseer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Citeseer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalizeFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/datasets/planetoid.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, name, split, num_train_per_class, num_val, num_test, transform, pre_transform)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'public'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'full'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geom-gcn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NormalizeFeatures' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K4Rdpo3NHt_R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}